%% Project 5
%
% EE 516 - Pattern Recognition
% Spring 2023
%
% Group 4: Nathan Jaggers, Nicholas Brunet, Jordan Rubio Perlas
%
% Description: See coresponding document <Can add description later>
%% Part 2
close all;
clear;
clc;

%%
% load data set
wdbc = importdata("wdbc.data");

%separate benign and malignant
pos_data = wdbc.data((wdbc.textdata(:,2))=="M",:);
neg_data = wdbc.data((wdbc.textdata(:,2))=="B",:);

%%
%create histograms to compare positive and negative data to find good
%discriminant features

for feature=1:30
    figure;
    hold on;
    histogram(pos_data(:,feature));
    histogram(neg_data(:,feature));
    xlabel("Value");
    ylabel("Frequency");
    figtitle = sprintf("Feature %d")
    title("Feature ",feature);
    hold off;
end

%%
% create data set for training and test

pos80 = round(length(pos_data)*0.8);
neg80 = round(length(neg_data)*0.8);

pos_Train = (pos_data(1:pos80,:));
neg_Train = (neg_data(1:neg80,:));

pos_Test = (pos_data(pos80:length(pos_data),:));
neg_Test = (neg_data(neg80:length(neg_data),:));

train_data = [pos_Train; neg_Train];
test_data = [pos_Test; neg_Test];

%getting prior probabilities from ratios in training data
% pos_prior = pos80/(pos80+neg80);
% neg_prior = neg80/(pos80+neg80);

%%
%ones that we like: 28, 23, 21ish, 8, 3

%trying to use features 8 and 28 
%make bayesian characteristics mu and sigma
feature_1 = 8;
feature_2 = 28;
pos_feat = [pos_Train(:,feature_1) pos_Train(:,feature_2)];
neg_feat = [neg_Train(:,feature_1) neg_Train(:,feature_2)];

%%
%training and set up for dichotomizer
[X, Y, mu_pos, cov_pos, prior_pos, mu_neg, cov_neg, prior_neg] = feat_details(pos_feat,neg_feat); 

%using dichotomizer
[predict,~] = dichotomizer(X, Y, mu_pos, cov_pos, prior_pos, mu_neg, cov_neg, prior_neg);

%showing results through confusion matrix
C = confusionmat(Y, predict);
confusionchart(C,["Benign","Malignant"]);

%%
%using previous training on test set

%make test set feature vectors 
pos_feat_test = [pos_Test(:,feature_1) pos_Test(:,feature_2)];
neg_feat_test = [neg_Test(:,feature_1) neg_Test(:,feature_2)];

%get dataset and augmented matrix from test features
[X_test, Y_test, ~] = feat_details(pos_feat_test,neg_feat_test); 

%classify test set
[predict,~] = dichotomizer(X_test, Y_test, mu_pos, cov_pos, prior_pos, mu_neg, cov_neg, prior_neg);

%showing results through confusion matrix (TP, TN, FP, FN)
C = confusionmat(Y_test, predict);
confusionchart(C,["Benign","Malignant"]);

%%
%ROC curve
prior_list = 0:0.1:1;
tp_list = length(prior_list);
fp_list = length(prior_list);

for i = 1:length(prior_list)
%gather predictions for different priors
[predict,~] = dichotomizer(X_test, Y_test, mu_pos, cov_pos, prior_pos, mu_neg, cov_neg, prior_neg);

%collect TP and FP info for each set of priors
C = confusionmat(Y_test, predict);
end

%%
%classify test set
[predict,~] = dichotomizer(X_test, Y_test, mu_pos, cov_pos, prior_pos, mu_neg, cov_neg, prior_neg);

%showing results through confusion matrix (TP, TN, FP, FN)
C = confusionmat(Y_test, predict);

%%
%set up for dichotomizer
function [dataset, classification, w1_mean, w1_cov, w1_Prior, w2_mean, w2_cov, w2_Prior] = feat_details(w1_features, w2_features)
    %calculate mean and cov to train dichotomizer
    w1_mean = mean(w1_features)';
    w2_mean = mean(w2_features)';

    w1_cov = cov(w1_features);
    w2_cov = cov(w2_features);

    %priors section
    w1_samples = size(w1_features,1);
    w2_samples = size(w2_features,1);
    w1_Prior = w1_samples/(w1_samples+w2_samples);
    w2_Prior = w2_samples/(w1_samples+w2_samples);

    %create input matrix and augmented matrix
    dataset = [w1_features; w2_features]; %input
    classification = [ones(size(w1_features, 1), 1); zeros(size(w2_features, 1), 1)]; %augmented (Y)
end

%general dichotomizer
function [prediction, accuracy] = dichotomizer(dataset, classification, w1_mean, w1_cov, w1_Prior, w2_mean, w2_cov, w2_Prior)
    %dataset - input data to be classified
    %classification - true classification of samples
    %w1_mean  - mean for class 1 
    %w1_cov   - covariance for class 2
    %w1_Prior - prior for class 1
    %w2_mean  - mean for class 2
    %w2_cov   - covariance for class 2
    %w2_Prior - prior for class 2

    %create class prediction matrix
    prediction = [zeros(size(classification, 1), 1)];

    %initialize correct counter
    correct = 0;
    
    for i = 1:size(dataset, 1)
        x = dataset(i,:)';
        y = classification(i);
        g1_result = g(x, w1_mean, w1_cov, w1_Prior);
        g2_result = g(x, w2_mean, w2_cov, w2_Prior);
        prediction(i) = g1_result - g2_result > 0;
        correct = correct + (prediction(i) == y);
    end
    accuracy = correct / size(dataset, 1);
    fprintf("Accuracy: %.2f\n", accuracy);
end

% Calculate parameters once in separate function if this takes too long
function result = g(x, mean, cov, P)
    cov_i = inv(cov);
    W = -0.5 * cov_i;
    w = cov_i * mean;
    w0 = -0.5 * (mean' * cov_i * mean) - 0.5 * log(det(cov)) + log(P);
    result = x'*W*x + w'*x + w0;
end
